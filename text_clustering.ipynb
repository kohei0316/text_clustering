{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import MeCab\n",
    "mecab = MeCab.Tagger(' -d /usr/local/lib/mecab/dic/mecab-ipadic-neologd')\n",
    "mecab.parse(\"\")  # 追加\n",
    "from gensim import corpora, matutils, models\n",
    "import scipy.cluster.hierarchy as hcluster\n",
    "from sklearn.cluster import KMeans\n",
    "import collections\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ↓ 単語辞書（text_clustering_dic.txt）を作成する関数 ↓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    node = mecab.parseToNode(text)\n",
    "    while node:\n",
    "        str = node.surface.lower()\n",
    "        if str != '':\n",
    "            yield str\n",
    "        node = node.next\n",
    "        \n",
    "# 形態素解析\n",
    "def keitaiso(text):\n",
    "    node = mecab.parseToNode(text)\n",
    "    word=[]\n",
    "    while node:\n",
    "        # 単語を取得\n",
    "        word.append(node.surface)\n",
    "        # 次の単語に進める\n",
    "        node = node.next\n",
    "    return word\n",
    "        \n",
    "def get_word_main(content):\n",
    "    '''一つの記事を形態素解析して返す'''\n",
    "    return [token for token in tokenize(content)]\n",
    "\n",
    "def get_words(sentence_list):\n",
    "    '''記事群のdictについて、形態素解析してリストにして返す'''\n",
    "    ret = []\n",
    "    for content in sentence_list:\n",
    "        ret.append(get_word_main(content))\n",
    "    return ret\n",
    "\n",
    "# 辞書生成\n",
    "def make_dictionary(sentence_list, name):\n",
    "    words = get_words(sentence_list)\n",
    "    dictionary = corpora.Dictionary(words)\n",
    "    dictionary.save_as_text(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ↓ Bag-of-Words ベクトル化してLSIで次元圧縮する関数 ↓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 全単語数の長さの配列で単語のベクトルを表現\n",
    "def vec2dense(vec, num_terms):\n",
    "    return list(matutils.corpus2dense([vec], num_terms=num_terms).T[0])\n",
    "\n",
    "# lsiで次元圧縮\n",
    "def lsi_model_gen(bow_list, num_terms):\n",
    "    lsi_list = []\n",
    "    lsi_model = models.LsiModel(bow_list, num_topics=num_terms)\n",
    "    for s in bow_list:\n",
    "        lsi_list.append(lsi_model[s])\n",
    "\n",
    "    return lsi_list\n",
    "\n",
    "def get_bow_list(words_of_each_fund, dictionary):\n",
    "    bow_list_each_fund = []\n",
    "    for s in words_of_each_fund:\n",
    "        bow = dictionary.doc2bow(s)\n",
    "        bow_list_each_fund.append(bow)\n",
    "    return bow_list_each_fund"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ↓ クラスタリング ↓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clustering(each_sentence_list, thresh, dictionary):\n",
    "    # BoW でベクトル化\n",
    "    words_of_each_fund = get_words(each_sentence_list) #分かち書きされた単語群を取得\n",
    "    bow_list_each_fund = get_bow_list(words_of_each_fund, dictionary)\n",
    "\n",
    "    # LSIを使って次元を5に圧縮してる （例） [0, 1, 1, 0, 1]\n",
    "    dimension = 5\n",
    "    lsi_list = lsi_model_gen(bow_list_each_fund, dimension)\n",
    "\n",
    "    # dimensionの次元の配列としてデータを保存。\n",
    "    data_all = [vec2dense(l, dimension) for l in lsi_list]\n",
    "\n",
    "    # thresh = 閾値\n",
    "    clusters = hcluster.fclusterdata(data_all, thresh, criterion=\"distance\")\n",
    "\n",
    "    each_sentence_clusters_dict = defaultdict(dict)\n",
    "\n",
    "    for i in range(len(set(clusters))):\n",
    "        each_sentence_clusters_dict[i] = []\n",
    "\n",
    "    for i, j in enumerate(clusters):\n",
    "        print(i, j)\n",
    "        new = each_sentence_clusters_dict[j-1]\n",
    "        new.append(each_sentence_list[i])\n",
    "        each_sentence_clusters_dict[j-1] = new\n",
    "\n",
    "    return each_sentence_clusters_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# メイン関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_list = [\n",
    "    '“垣根”は相手が作っているのではなく、自分が作っている。',\n",
    "    '「ああ、ここにおれの進むべき道があった！ようやく掘り当てた！」こういう感投詞を心の底から叫び出される時、貴方がたははじめて心を安んずる事ができるのだろう。',\n",
    "    '３０分ぐらいでは何もできないと考えているより、世の中の一番つまらぬことでもする方がまさっている。',\n",
    "    'アイデアは、それを一心に求めてさえいれば必ず生まれる。',\n",
    "    '貴方がたとえ氷のように潔癖で雪のように潔白であろうとも、世の悪口はまぬがれまい。',\n",
    "    '貴方がたの人間性を心にとどめ、そして他のことを忘れよ。',\n",
    "    '貴方と世の中との戦いなら、世の中のほうに賭けなさい。',\n",
    "    '貴方の遊びに言い訳はいらない。言い訳を決して言うな。',\n",
    "    'いまの世の中、人間が人間を見捨てているのよね。親が子を、子が親を、兄が弟を、友が友を、隣人が隣人を。',\n",
    "    'おのれの得るところを軽んずるなかれ。',\n",
    "    'この世は絶え間のないシーソーだ。',\n",
    "    'すべては、待っている間に頑張った人のもの。',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2\n",
      "1 5\n",
      "2 3\n",
      "3 1\n",
      "4 4\n",
      "5 1\n",
      "6 1\n",
      "7 1\n",
      "8 6\n",
      "9 1\n",
      "10 1\n",
      "11 1\n"
     ]
    }
   ],
   "source": [
    "# 単語辞書作成\n",
    "make_dictionary(text_list, \"text_clustering_dic.txt\")\n",
    "dictionary = corpora.Dictionary.load_from_text(\"text_clustering_dic.txt\")\n",
    "\n",
    "# クラスタリング\n",
    "each_sentence_clusters_dict = clustering(text_list, 2.0, dictionary) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {0: ['アイデアは、それを一心に求めてさえいれば必ず生まれる。',\n",
       "              '貴方がたの人間性を心にとどめ、そして他のことを忘れよ。',\n",
       "              '貴方と世の中との戦いなら、世の中のほうに賭けなさい。',\n",
       "              '貴方の遊びに言い訳はいらない。言い訳を決して言うな。',\n",
       "              'おのれの得るところを軽んずるなかれ。',\n",
       "              'この世は絶え間のないシーソーだ。',\n",
       "              'すべては、待っている間に頑張った人のもの。'],\n",
       "             1: ['“垣根”は相手が作っているのではなく、自分が作っている。'],\n",
       "             2: ['３０分ぐらいでは何もできないと考えているより、世の中の一番つまらぬことでもする方がまさっている。'],\n",
       "             3: ['貴方がたとえ氷のように潔癖で雪のように潔白であろうとも、世の悪口はまぬがれまい。'],\n",
       "             4: ['「ああ、ここにおれの進むべき道があった！ようやく掘り当てた！」こういう感投詞を心の底から叫び出される時、貴方がたははじめて心を安んずる事ができるのだろう。'],\n",
       "             5: ['いまの世の中、人間が人間を見捨てているのよね。親が子を、子が親を、兄が弟を、友が友を、隣人が隣人を。']})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "each_sentence_clusters_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
